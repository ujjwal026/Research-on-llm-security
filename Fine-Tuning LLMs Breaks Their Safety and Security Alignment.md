# Impact of Fine-Tuning AI Models on Security

## Key Risks

- 🚨 **Compliance** increases **3x** after fine-tuning.  
- ⚠️ **Harmfulness** increases **5x** in fine-tuned models.  
- 🔓 **Security safeguards weaken** post-fine-tuning.  
- 🚀 **Jailbreak success rate** increases **22x** post-fine-tuning.  

## Findings

| Model Variant            | Compliance Score | Harmfulness Score |
| ------------------------ | ---------------- | ----------------- |
| **Llama-2-7B**           | 0.54             | 0.10              |
| **AdaptLLM-Biomedicine** | 1.66             | 1.06              |
| **AdaptLLM-Finance**     | 1.73             | 1.05              |
| **AdaptLLM-Law**         | 1.72             | 1.10              |

## Conclusion

Fine-tuning improves domain expertise but **weakens AI security**, reactivates suppressed risks, disrupts safeguards, and dramatically increases jailbreak vulnerabilities.

---

📌 **Stay secure**: Implement external safety layers and continuous monitoring to mitigate risks.
